{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6700fd2-dc5d-4749-b91d-8e895e7469e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69add916-c409-418e-92cf-8c4e4c42eeda",
   "metadata": {},
   "outputs": [],
   "source": [
    "pinecone_api_key = \"\" # Your pinecone api key\n",
    "pc = Pinecone(api_key=pinecone_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cfc263a-5239-4eb5-9ee7-e7606c34c2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name = \"\" # pinecone index name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72cd8092-b414-4434-b6f0-e369f0475bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not pc.has_index(index_name):\n",
    "    pc.create_index_for_model(\n",
    "        name=index_name,\n",
    "        cloud=\"aws\",\n",
    "        region=\"us-east-1\",\n",
    "        embed={\n",
    "            \"model\": \"llama-text-embed-v2\",\n",
    "            \"field_map\": {\"text\": \"chunk_text\"}\n",
    "        }\n",
    "    )\n",
    "    print(f\"Creating index {index_name}... waiting 10 sec\")\n",
    "    time.sleep(10)\n",
    "else:\n",
    "    print(f\"Index {index_name} already exists.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81d695b-ba25-4f45-99a4-02010ea9abe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_path = \"\" # your files e.g., resume, certificate etc.\n",
    "source_name = \"\" # pinecone metadata\n",
    "\n",
    "loader = PyPDFLoader(document_path)\n",
    "pages = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=50\n",
    ")\n",
    "chunks = text_splitter.split_documents(pages)\n",
    "print(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8312cfe-6dee-4175-bcc5-ff984fdf24a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "records = []\n",
    "for i, chunk in enumerate(chunks):\n",
    "    chunk_text = chunk.page_content\n",
    "    record = {\n",
    "        \"_id\": f\"{source_name}_chunk_{i}\",\n",
    "        \"chunk_text\": chunk_text,\n",
    "        \"source\": source_name,\n",
    "        \"page_number\": chunk.metadata.get(\"page\", -1)\n",
    "    }\n",
    "    records.append(record)\n",
    "\n",
    "dense_index = pc.Index(index_name)\n",
    "namespace = \"\" # pinecone namespace\n",
    "\n",
    "dense_index.upsert_records(namespace, records)\n",
    "print(f\"Uploaded {len(records)} records.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fae0e99-dcbc-4f1f-beba-84317c37640c",
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(5)\n",
    "stats = dense_index.describe_index_stats()\n",
    "print(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add22af2-5bd5-4d73-a6ca-1614fd31c460",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e052114c-e709-4c4f-ac4c-0ddc5c1983b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_huggingface(prompt):\n",
    "    HUGGINGFACE_API_KEY = \"\"  # your huggingface api token\n",
    "    API_URL = \"https://api-inference.huggingface.co/models/HuggingFaceH4/zephyr-7b-beta\"\n",
    "\n",
    "    headers = {\"Authorization\": f\"Bearer {HUGGINGFACE_API_KEY}\"}\n",
    "\n",
    "    payload = {\n",
    "        \"inputs\": prompt,\n",
    "        \"parameters\": {\n",
    "            \"max_new_tokens\": 256\n",
    "        }\n",
    "    }\n",
    "\n",
    "    response = requests.post(API_URL, headers=headers, json=payload)\n",
    "\n",
    "    # Debugging aid:\n",
    "    # print(\"Status code:\", response.status_code)\n",
    "    # print(\"Raw response text:\", response.text)\n",
    "\n",
    "    try:\n",
    "        return response.json()\n",
    "    except Exception as e:\n",
    "        print(\"Error decoding JSON:\", e)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1853859d-5f69-48c9-a563-fe27fec53ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_llm_prompt(top_chunks, user_question):\n",
    "    # Build the chunk text first\n",
    "    chunks_text = \"\\n\\n\".join(top_chunks)  # double newline looks more natural than --- separators\n",
    "\n",
    "    # Build the full prompt with clear delimiters and Answer token\n",
    "    prompt = f\"\"\"\n",
    "You are an AI assistant. Here is information from Victor's resume:\n",
    "\n",
    "=== BEGIN RESUME ===\n",
    "{chunks_text}\n",
    "=== END RESUME ===\n",
    "\n",
    "Now answer the following question concisely:\n",
    "\n",
    "Question: {user_question}\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8466a01a-7e22-44f7-85f6-1f63174a82fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What programming languages does X's know?\"\n",
    "\n",
    "# Run search\n",
    "results = dense_index.search(\n",
    "    namespace=namespace,   # same namespace used in upsert\n",
    "    query={\n",
    "        \"top_k\": 5,\n",
    "        \"inputs\": {\n",
    "            \"text\": query\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "# Print results\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae328b72-f7f8-457e-a791-4f49cf8b5e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_chunks = []\n",
    "\n",
    "for hit in results['result']['hits'][:5]:  # Top 5 chunks\n",
    "    chunk_text = hit['fields']['chunk_text']\n",
    "    top_chunks.append(chunk_text)\n",
    "\n",
    "print(top_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68eb494-eaf9-4125-a089-943145e5e606",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_question = \"What programming languages does X's know?\"\n",
    "\n",
    "# Build prompt\n",
    "prompt = build_llm_prompt(top_chunks, user_question)\n",
    "\n",
    "# Send to Hugging Face\n",
    "response = query_huggingface(prompt)\n",
    "\n",
    "# Extract clean answer\n",
    "generated_text = response[0]['generated_text']\n",
    "if \"Answer:\" in generated_text:\n",
    "    answer = generated_text.split(\"Answer:\")[-1].strip()\n",
    "else:\n",
    "    answer = generated_text.strip()\n",
    "\n",
    "# Final one-line print\n",
    "print(f\"LLM Answer: {answer}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
